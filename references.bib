@misc{cohen2024posteriorsamplingmeaningfuldiversity,
      title={From Posterior Sampling to Meaningful Diversity in Image Restoration}, 
      author={Noa Cohen and Hila Manor and Yuval Bahat and Tomer Michaeli},
      year={2024},
      eprint={2310.16047},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.16047}, 
}

@misc{augustin2024digindiffusionguidanceinvestigating,
      title={DiG-IN: Diffusion Guidance for Investigating Networks -- Uncovering Classifier Differences Neuron Visualisations and Visual Counterfactual Explanations}, 
      author={Maximilian Augustin and Yannic Neuhaus and Matthias Hein},
      year={2024},
      eprint={2311.17833},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.17833}, 
}

@misc{rombach2022highresolutionimagesynthesislatent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@misc{ho2022classifierfreediffusionguidance,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.12598}, 
}

@misc{dreyer2025mechanisticunderstandingvalidationlarge,
      title={Mechanistic understanding and validation of large AI models with SemanticLens}, 
      author={Maximilian Dreyer and Jim Berend and Tobias Labarta and Johanna Vielhaben and Thomas Wiegand and Sebastian Lapuschkin and Wojciech Samek},
      year={2025},
      eprint={2501.05398},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.05398}, 
}

@misc{neuhaus2023spuriousfeatureslargescale,
      title={Spurious Features Everywhere -- Large-Scale Detection of Harmful Spurious Features in ImageNet}, 
      author={Yannic Neuhaus and Maximilian Augustin and Valentyn Boreiko and Matthias Hein},
      year={2023},
      eprint={2212.04871},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.04871}, 
}

@article{Lapuschkin_2019,
   title={Unmasking Clever Hans predictors and assessing what machines really learn},
   volume={10},
   ISSN={2041-1723},
   url={http://dx.doi.org/10.1038/s41467-019-08987-4},
   DOI={10.1038/s41467-019-08987-4},
   number={1},
   journal={Nature Communications},
   publisher={Springer Science and Business Media LLC},
   author={Lapuschkin, Sebastian and Wäldchen, Stephan and Binder, Alexander and Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
   year={2019},
   month=mar }

@book{pfungst1911cleverHans,
  author    = {Pfungst, Oskar},
  title     = {Clever Hans (the Horse of Mr. Von Osten): A Contribution to Experimental Animal and Human Psychology},
  volume    = {8},
  publisher = {Holt, Rinehart and Winston},
  year      = {1911}
}

@misc{jeanneret2022diffusionmodelscounterfactualexplanations,
      title={Diffusion Models for Counterfactual Explanations}, 
      author={Guillaume Jeanneret and Loïc Simon and Frédéric Jurie},
      year={2022},
      eprint={2203.15636},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.15636}, 
}

@misc{sobieski2024rethinkingvisualcounterfactualexplanations,
      title={Rethinking Visual Counterfactual Explanations Through Region Constraint}, 
      author={Bartlomiej Sobieski and Jakub Grzywaczewski and Bartlomiej Sadlej and Matthew Tivnan and Przemyslaw Biecek},
      year={2024},
      eprint={2410.12591},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.12591}, 
}

@misc{chung2024diffusionposteriorsamplinggeneral,
      title={Diffusion Posterior Sampling for General Noisy Inverse Problems}, 
      author={Hyungjin Chung and Jeongsol Kim and Michael T. Mccann and Marc L. Klasky and Jong Chul Ye},
      year={2024},
      eprint={2209.14687},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2209.14687}, 
}

@misc{batzolis2021conditionalimagegenerationscorebased,
      title={Conditional Image Generation with Score-Based Diffusion Models}, 
      author={Georgios Batzolis and Jan Stanczuk and Carola-Bibiane Schönlieb and Christian Etmann},
      year={2021},
      eprint={2111.13606},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.13606}, 
}

@misc{song2021scorebasedgenerativemodelingstochastic,
      title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
      author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
      year={2021},
      eprint={2011.13456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.13456}, 
}

@inproceedings{robbins1992empirical,
    author={Robbins, Herbert E},
    title={{An empirical Bayes approach to statistics}},
    booktitle={Breakthroughs in Statistics: Foundations and basic theory},
    year={1992},
}

@inproceedings{chung2022improving,
  title={Improving diffusion models for inverse problems using manifold constraints},
  author={Chung, Hyungjin and Sim, Byeongsu and Ryu, Dohoon and Ye, Jong Chul},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{weng2024fast,
    title={Fast diffusion-based counterfactuals for shortcut removal and generation},
    author={Weng, Nina and Pegios, Paraskevas and Feragen, Aasa and Petersen, Eike and Bigdeli, Siavash},
    booktitle = {European Conference on Computer Vision},
    year = {2024}
}

@book{anderson1982reverse,
title={Reverse-time diffusion equation models},
author={Anderson, Brian DO},
volume={12},
year={1982},
publisher = {Stochastic Processes and their Applications, Elsevier}
}

@inproceedings{jeanneret2022diffusion,
  title={Diffusion models for counterfactual explanations},
  author={Jeanneret, Guillaume and Simon, Lo{\"\i}c and Jurie, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={858--876},
  year={2022}
}

@misc{szegedy2014intriguingpropertiesneuralnetworks,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      eprint={1312.6199},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1312.6199}, 
}

# CVPR 2025
@inproceedings{yao2025vavae,
  title={Reconstruction vs. generation: Taming optimization dilemma in latent diffusion models},
  author={Yao, Jingfeng and Yang, Bin and Wang, Xinggang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025}
}

# NeurIPS 2024
@article{yao2024fasterdit,
  title={Fasterdit: Towards faster diffusion transformers training without architecture modification},
  author={Yao, Jingfeng and Wang, Cheng and Liu, Wenyu and Wang, Xinggang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={56166--56189},
  year={2024}
}

@misc{paperswithcode_imagenet,
    title = {State-of-the-Art: Image Generation on ImageNet 256x256},
    author = {{Papers With Code}},
    howpublished = {\url{https://paperswithcode.com/sota/image-generation-on-imagenet-256x256}},
    year = {2024},
    note = {Accessed: April 6, 2025}
}

@misc{dhariwal2021diffusionmodelsbeatgans,
      title={Diffusion Models Beat GANs on Image Synthesis}, 
      author={Prafulla Dhariwal and Alex Nichol},
      year={2021},
      eprint={2105.05233},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.05233}, 
}

@inproceedings{leask2025sparse,
      title={Sparse Autoencoders Do Not Find Canonical Units of Analysis},
      author={Patrick Leask and Bart Bussmann and Michael T Pearce and Joseph Isaac Bloom and Curt Tigges and Noura Al Moubayed and Lee Sharkey and Neel Nanda},
      booktitle={The Thirteenth International Conference on Learning Representations},
      year={2025},
      url={https://openreview.net/forum?id=9ca9eHNrdH}
}

@misc{mordvintsev2015deepdream,
  author       = {Alexander Mordvintsev and Christopher Olah and Mike Tyka},
  title        = {DeepDream – A Code Example for Visualizing Neural Networks},
  year         = {2015},
  howpublished = {\url{https://research.google/blog/deepdream-a-code-example-for-visualizing-neural-networks/}},
  note         = {Accessed: 2025-04-18}
}

@article{olah2017feature,
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  title = {Feature Visualization},
  journal = {Distill},
  year = {2017},
  note = {https://distill.pub/2017/feature-visualization},
  doi = {10.23915/distill.00007}
}

@article{Popescu2005ExposingDF,
  title={Exposing Digital Forgeries by Detecting Traces of Resampling},
  author={Popescu, Alin C. and Farid, Hany},
  journal={IEEE Transactions on Signal Processing},
  volume={53},
  number={2},
  pages={758--767},
  year={2005},
  publisher={IEEE},
  doi={10.1109/TSP.2004.839932}
}

@misc{ronneberger2015unetconvolutionalnetworksbiomedical,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}

@misc{oord2018neuraldiscreterepresentationlearning,
      title={Neural Discrete Representation Learning}, 
      author={Aaron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
      year={2018},
      eprint={1711.00937},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.00937}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{zhang2019detectingsimulatingartifactsgan,
      title={Detecting and Simulating Artifacts in GAN Fake Images}, 
      author={Xu Zhang and Svebor Karaman and Shih-Fu Chang},
      year={2019},
      eprint={1907.06515},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1907.06515}, 
}

@misc{wang2023dirediffusiongeneratedimagedetection,
      title={DIRE for Diffusion-Generated Image Detection}, 
      author={Zhendong Wang and Jianmin Bao and Wengang Zhou and Weilun Wang and Hezhen Hu and Hong Chen and Houqiang Li},
      year={2023},
      eprint={2303.09295},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.09295}, 
}

@article{zhang2023diffusion,
  title={Diffusion noise feature: Accurate and fast generated image detection},
  author={Zhang, Yichi and Xu, Xiaogang},
  journal={arXiv preprint arXiv:2312.02625},
  year={2023}
}

@misc{goodfellow2014generativeadversarialnetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}

@misc{ho2020denoisingdiffusionprobabilisticmodels,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}

@misc{simonyan2014deepinsideconvolutionalnetworks,
      title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}, 
      author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
      year={2014},
      eprint={1312.6034},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1312.6034}, 
}

@misc{kim2018interpretabilityfeatureattributionquantitative,
      title={Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)}, 
      author={Been Kim and Martin Wattenberg and Justin Gilmer and Carrie Cai and James Wexler and Fernanda Viegas and Rory Sayres},
      year={2018},
      eprint={1711.11279},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1711.11279}, 
}

@misc{sundararajan2017axiomaticattributiondeepnetworks,
      title={Axiomatic Attribution for Deep Networks}, 
      author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
      year={2017},
      eprint={1703.01365},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.01365}, 
}

@INPROCEEDINGS{8237336,
  author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}, 
  year={2017},
  volume={},
  number={},
  pages={618-626},
  keywords={Visualization;Cats;Dogs;Computer architecture;Knowledge discovery},
  doi={10.1109/ICCV.2017.74}}

@misc{ribeiro2016whyitrustyou,
      title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1602.04938},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1602.04938}, 
}

@misc{lundberg2017unifiedapproachinterpretingmodel,
      title={A Unified Approach to Interpreting Model Predictions}, 
      author={Scott Lundberg and Su-In Lee},
      year={2017},
      eprint={1705.07874},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.07874}, 
}

@misc{bau2017networkdissectionquantifyinginterpretability,
      title={Network Dissection: Quantifying Interpretability of Deep Visual Representations}, 
      author={David Bau and Bolei Zhou and Aditya Khosla and Aude Oliva and Antonio Torralba},
      year={2017},
      eprint={1704.05796},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.05796}, 
}

@misc{ghorbani2019automaticconceptbasedexplanations,
      title={Towards Automatic Concept-based Explanations}, 
      author={Amirata Ghorbani and James Wexler and James Zou and Been Kim},
      year={2019},
      eprint={1902.03129},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1902.03129}, 
}

@ARTICLE{6795935,
  author={Vincent, Pascal},
  journal={Neural Computation}, 
  title={A Connection Between Score Matching and Denoising Autoencoders}, 
  year={2011},
  volume={23},
  number={7},
  pages={1661-1674},
  keywords={},
  doi={10.1162/NECO_a_00142}}

@inproceedings{song2023pseudoinverse,
  title={Pseudoinverse-Guided Diffusion Models for Inverse Problems},
  author={Song, Jiaming and Vahdat, Arash and Mardani, Morteza and Kautz, Jan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://openreview.net/forum?id=9_gsMA8MRKQ}
}

@article{erhan2009visualizing,
author = {Erhan, Dumitru and Bengio, Y. and Courville, Aaron and Vincent, Pascal},
year = {2009},
month = {01},
pages = {},
title = {Visualizing Higher-Layer Features of a Deep Network},
journal = {Technical Report, Univeristé de Montréal}
}

@misc{mahendran2014understandingdeepimagerepresentations,
      title={Understanding Deep Image Representations by Inverting Them}, 
      author={Aravindh Mahendran and Andrea Vedaldi},
      year={2014},
      eprint={1412.0035},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1412.0035}, 
}

@misc{gupta2018shampoopreconditionedstochastictensor,
      title={Shampoo: Preconditioned Stochastic Tensor Optimization}, 
      author={Vineet Gupta and Tomer Koren and Yoram Singer},
      year={2018},
      eprint={1802.09568},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.09568}, 
}

@misc{song2020generativemodelingestimatinggradients,
      title={Generative Modeling by Estimating Gradients of the Data Distribution}, 
      author={Yang Song and Stefano Ermon},
      year={2020},
      eprint={1907.05600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1907.05600}, 
}

@misc{shinkle2025visualizingcontrollingcorticalresponses,
      title={Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization}, 
      author={Matthew W. Shinkle and Mark D. Lescroart},
      year={2025},
      eprint={2506.04379},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2506.04379}, 
}

@misc{nanfack2023adversarialattacksinterpretationneuron,
      title={Adversarial Attacks on the Interpretation of Neuron Activation Maximization}, 
      author={Geraldin Nanfack and Alexander Fulleringer and Jonathan Marty and Michael Eickenberg and Eugene Belilovsky},
      year={2023},
      eprint={2306.07397},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2306.07397}, 
}

@misc{zhu2025representationunderstandingactivationmaximization,
      title={Representation Understanding via Activation Maximization}, 
      author={Hongbo Zhu and Angelo Cangelosi},
      year={2025},
      eprint={2508.07281},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.07281}, 
}

@book{lee2013smooth,
  title={Introduction to Smooth Manifolds},
  author={Lee, John M.},
  edition={2nd},
  year={2013},
  publisher={Springer},
  series={Graduate Texts in Mathematics},
  volume={218},
  isbn={978-1-4419-9982-5}
}

@book{milnor1965topology,
  title={Topology from the Differentiable Viewpoint},
  author={Milnor, John W.},
  year={1965},
  publisher={University Press of Virginia},
  isbn={978-0-691-04833-8}
}

@article{fort2017gaussian,
  title={Gaussian Prototypes for One-Shot Learning},
  author={Fort, Stanislav},
  journal={arXiv preprint arXiv:1708.05115},
  year={2017},
  url={https://arxiv.org/abs/1708.05115}
}

@misc{joseph2025prismaopensourcetoolkit,
      title={Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video}, 
      author={Sonia Joseph and Praneet Suresh and Lorenz Hufe and Edward Stevinson and Robert Graham and Yash Vadi and Danilo Bzdok and Sebastian Lapuschkin and Lee Sharkey and Blake Aaron Richards},
      year={2025},
      eprint={2504.19475},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.19475}, 
}
@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}


@inproceedings{10.5555/3692070.3692231,
author = {Biecek, Przemyslaw and Samek, Wojciech},
title = {Position: explain to question not to justify},
year = {2024},
publisher = {JMLR.org},
abstract = {Explainable Artificial Intelligence (XAI) is a young but very promising field of research. Unfortunately, the progress in this field is currently slowed down by divergent and incompatible goals. We separate various threads tangled within the area of XAI into two complementary cultures of human/value-oriented explanations (BLUE XAI) and model/validation-oriented explanations (RED XAI). This position paper argues that the area of RED XAI is currently under-explored, i.e., more methods for explainability are desperately needed to question models (e.g., extract knowledge from well-performing models as well as spotting and fixing bugs in faulty models), and the area of RED XAI hides great opportunities and potential for important research necessary to ensure the safety of AI systems. We conclude this paper by presenting promising challenges in this area.},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {161},
numpages = {11},
location = {Vienna, Austria},
series = {ICML'24}
}

@article{10.1145/3236009,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {93},
numpages = {42},
keywords = {Open the black box, explanations, interpretability, transparent models}
}
@inbook{Holzinger2022a,
  author = {Holzinger, Andreas and Goebel, Randy and Fong, Ruth and Moon, Taesup and Müller, Klaus-Robert and Samek, Wojciech},
  title = {xxAI - Beyond Explainable AI},
  booktitle = {xxAI - Beyond Explainable AI},
  editor = {Holzinger, Andreas and Goebel, Randy and Fong, Ruth and Moon, Taesup and Müller, Klaus-Robert and Samek, Wojciech},
  year = {2022},
  publisher = {Springer},
  pages = {3--10},
  doi = {10.1007/978-3-031-04083-2_1}
}

@Inbook{Holzinger2022,
author="Holzinger, Andreas
and Saranti, Anna
and Molnar, Christoph
and Biecek, Przemyslaw
and Samek, Wojciech",
editor="Holzinger, Andreas
and Goebel, Randy
and Fong, Ruth
and Moon, Taesup
and M{\"u}ller, Klaus-Robert
and Samek, Wojciech",
title="Explainable AI Methods - A Brief Overview",
bookTitle="xxAI - Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="13--38",
abstract="Explainable Artificial Intelligence (xAI) is an established field with a vibrant community that has developed a variety of very successful approaches to explain and interpret predictions of complex machine learning models such as deep neural networks. In this article, we briefly introduce a few selected methods and discuss them in a short, clear and concise way. The goal of this article is to give beginners, especially application engineers and data scientists, a quick overview of the state of the art in this current topic. The following 17 methods are covered in this chapter: LIME, Anchors, GraphLIME, LRP, DTD, PDA, TCAV, XGNN, SHAP, ASV, Break-Down, Shapley Flow, Textual Explanations of Visual Models, Integrated Gradients, Causal Models, Meaningful Perturbations, and X-NeSyL.",
isbn="978-3-031-04083-2",
doi="10.1007/978-3-031-04083-2_2",
url="https://doi.org/10.1007/978-3-031-04083-2_2"
}

@Inbook{Kolek2022,
author="Kolek, Stefan
and Nguyen, Duc Anh
and Levie, Ron
and Bruna, Joan
and Kutyniok, Gitta",
editor="Holzinger, Andreas
and Goebel, Randy
and Fong, Ruth
and Moon, Taesup
and M{\"u}ller, Klaus-Robert
and Samek, Wojciech",
title="A Rate-Distortion Framework for Explaining Black-Box Model Decisions",
bookTitle="xxAI - Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="91--115",
abstract="We present the Rate-Distortion Explanation (RDE) framework, a mathematically well-founded method for explaining black-box model decisions. The framework is based on perturbations of the target input signal and applies to any differentiable pre-trained model such as neural networks. Our experiments demonstrate the framework's adaptability to diverse data modalities, particularly images, audio, and physical simulations of urban environments.",
isbn="978-3-031-04083-2",
doi="10.1007/978-3-031-04083-2_6",
url="https://doi.org/10.1007/978-3-031-04083-2_6"
}


@misc{zhou2022interpretinggenerativeadversarialnetworks,
      title={Interpreting Generative Adversarial Networks for Interactive Image Generation}, 
      author={Bolei Zhou},
      year={2022},
      eprint={2108.04896},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2108.04896}, 
}

@Inbook{Karimi2022,
author="Karimi, Amir-Hossein
and von K{\"u}gelgen, Julius
and Sch{\"o}lkopf, Bernhard
and Valera, Isabel",
title="Towards Causal Algorithmic Recourse",
bookTitle="xxAI - Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="139--166",
abstract="Algorithmic recourse is concerned with aiding individuals who are unfavorably treated by automated decision-making systems to overcome their hardship, by offering recommendations that would result in a more favorable prediction when acted upon. Such recourse actions are typically obtained through solving an optimization problem that minimizes changes to the individual's feature vector, subject to various plausibility, diversity, and sparsity constraints. Whereas previous works offer solutions to the optimization problem in a variety of settings, they critically overlook real-world considerations pertaining to the environment in which recourse actions are performed.",
isbn="978-3-031-04083-2",
doi="10.1007/978-3-031-04083-2_8",
url="https://doi.org/10.1007/978-3-031-04083-2_8"
}

@inbook{inbook,
author = {Marcos, Diego and Kierdorf, Jana and Cheeseman, Ted and Tuia, Devis and Roscher, Ribana},
year = {2022},
month = {01},
pages = {297-313},
title = {A Whale’s Tail - Finding the Right Whale in an Uncertain World},
isbn = {978-3-031-04082-5},
doi = {10.1007/978-3-031-04083-2_15}
}

@inproceedings{
Inala2020Synthesizing,
title={Synthesizing Programmatic Policies that Inductively Generalize},
author={Jeevana Priya Inala and Osbert Bastani and Zenna Tavares and Armando Solar-Lezama},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1l8oANFDH}
}

@misc{verma2019programmaticallyinterpretablereinforcementlearning,
      title={Programmatically Interpretable Reinforcement Learning}, 
      author={Abhinav Verma and Vijayaraghavan Murali and Rishabh Singh and Pushmeet Kohli and Swarat Chaudhuri},
      year={2019},
      eprint={1804.02477},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1804.02477}, 
}

@article{D_az_Rodr_guez_2022,
   title={EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case},
   volume={79},
   ISSN={1566-2535},
   url={http://dx.doi.org/10.1016/j.inffus.2021.09.022},
   DOI={10.1016/j.inffus.2021.09.022},
   journal={Information Fusion},
   publisher={Elsevier BV},
   author={Díaz-Rodríguez, Natalia and Lamas, Alberto and Sanchez, Jules and Franchi, Gianni and Donadello, Ivan and Tabik, Siham and Filliat, David and Cruz, Policarpo and Montes, Rosana and Herrera, Francisco},
   year={2022},
   month=mar, pages={58–83} }

@misc{karimi2020algorithmicrecoursecounterfactualexplanations,
      title={Algorithmic Recourse: from Counterfactual Explanations to Interventions}, 
      author={Amir-Hossein Karimi and Bernhard Schölkopf and Isabel Valera},
      year={2020},
      eprint={2002.06278},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.06278}, 
}

@inbook{Tsai2022,
  author = {Tsai, Chun-Hua and Carroll, John M.},
  title = {Logic and Pragmatics in AI Explanation},
  booktitle = {xxAI - Beyond Explainable AI},
  year = {2022},
  pages = {387--396},
  doi = {10.1007/978-3-031-04083-2_18}
}

@inbook{Singh2022,
  author = {Singh, Chandan and Ha, Wooseok and Yu, Bin},
  title = {Interpreting and Improving Deep-Learning Models with Reality Checks},
  booktitle = {xxAI - Beyond Explainable AI},
  year = {2022},
  pages = {229--254},
  doi = {10.1007/978-3-031-04083-2_11}
}