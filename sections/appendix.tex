\appendix

\chapter{Appendix}\label{r:appendix}


\section{Supplementary Algorithmic Details}\label{appendix:infinite_optimization}
This section provides supplementary algorithmic details that complement the main algorithmic specification presented in the method chapter. The focus here is on implementation nuances and technical considerations that support the primary algorithm description.

\subsection{Key Algorithmic Adaptations}

The EquiDiff implementation introduces several important modifications to the original infinite optimization framework to suit invariant set generation requirements. Unlike the original text-conditioned approach, the method employs unconditional diffusion models with $C_t = \emptyset$ for all timesteps, relying entirely on the optimization process to guide generation toward the target invariant set. This unconditional approach eliminates the need for complex conditioning mechanisms while maintaining precise control over network activations.

The invariant set objective represents a fundamental departure from traditional diffusion guidance approaches. Instead of optimizing for text-image alignment or other external conditioning signals, the method minimizes the $L_2$ distance between $\mathcal{L}(x)$ and the target value $\mathcal{L}(\mathbf{x^*})$, ensuring membership in the same invariant set through direct activation matching. This objective design enables precise control over specific neural network components while maintaining the flexibility to target various network architectures and layer configurations.

Frequency domain filtering integration constitutes a novel contribution that addresses the fundamental challenge of adversarial solutions in optimization-based generation. The incorporation of low-pass filter $\mathcal{F}$ before computing the objective function ensures that invariant set membership is achieved through perceptually meaningful variations rather than high-frequency adversarial noise. This filtering mechanism operates as a regularization constraint that guides the optimization toward semantically coherent solutions.

The LightningDiT integration requires careful consideration of the specific sampling procedures and update rules that may differ from standard DDIM implementations. The denoising process follows the LightningDiT sampling procedure, which incorporates architectural optimizations and potentially different noise schedules that affect the gradient flow and optimization dynamics throughout the generation process.

\subsection{Computational Resource Management}

The infinite optimization approach demands sophisticated computational resource management to achieve practical scalability while maintaining solution quality. Gradient checkpointing implementation during the denoising loop reduces memory consumption while maintaining gradient flow through the entire diffusion process. This technique enables optimization through deep diffusion pipelines without prohibitive memory requirements, making the approach feasible on standard research hardware configurations.

Optimizer selection represents a critical design decision that significantly impacts convergence stability and solution quality. Empirical evaluation demonstrates that SGD exhibits superior convergence properties for invariant set generation compared to adaptive methods like Adam, particularly in the high-dimensional latent spaces characteristic of diffusion models. The inherent stochasticity of SGD updates provides beneficial exploration properties that help escape local minima corresponding to suboptimal invariant set members.

Step budget management balances computational cost with solution quality through careful parameter selection for both the step budget $B$ and threshold $\tau$ parameters. This approach enables early termination for efficient optimization landscapes while providing computational bounds for practical implementation. The dual termination criteria ensure that the algorithm can adapt to varying optimization difficulty across different invariant set generation tasks.

Dual loss computation provides robustness against adversarial solutions while maintaining semantic coherence in generated samples. Computing both filtered and unfiltered objective values throughout the optimization process ensures that solutions satisfy invariant set membership requirements across multiple frequency bands, preventing optimization from exploiting imperceptible high-frequency patterns that could compromise semantic meaningfulness.

\section{Level Set Theory Foundation}\label{appendix:level_sets}

Proposed \framework{} are mathematically equivalent to level sets from classical analysis. This connection provides theoretical grounding for the generative approach.

\subsection{Basic Definition}

For a function $f: \mathbb{R}^n \rightarrow \mathbb{R}$, the level set at value $c$ is:
\begin{equation}
L_c = \{x \in \mathbb{R}^n : f(x) = c\}
\end{equation}

This is exactly what we compute: all inputs $x$ that produce the same output value $c$.

\subsection{Neural Network Case}

For neural networks outputting vectors $\mathcal{L}_{\boldsymbol{\theta}}: \mathbb{R}^n \rightarrow \mathbb{R}^m$, proposed invariant sets are intersections of multiple level sets:
\begin{equation}
\mathbf{IS}(\mathbf{x^*}) = \bigcap_{i=1}^m \{x : [\mathcal{L}_{\boldsymbol{\theta}}(x)]_i = [\mathcal{L}_{\boldsymbol{\theta}}(\mathbf{x^*})]_i\}
\end{equation}

Each output dimension defines one level set; we find points lying on all of them simultaneously.

\subsection{Why This Works}

Level sets typically form smooth geometric surfaces when the function gradients are non-zero. Proposed diffusion model samples from these surfaces while staying within the natural image manifold. This geometric perspective explains why we can generate diverse yet valid samples from invariant sets.

\section{Implementation Details}\label{appendix:implementation}

This section provides the specific implementation parameters used throughout the experiments.

\subsection{Optimization Configuration}

Based on empirical evaluation across multiple experimental conditions, the optimization configuration employs SGD as the primary optimizer due to its demonstrated superior convergence stability compared to adaptive methods in the high-dimensional latent spaces characteristic of diffusion models. The learning rate is set to $\eta = 10$, which provides an optimal balance between convergence speed and optimization stability, enabling rapid progress toward invariant set membership while maintaining numerical stability throughout the gradient flow process.

The step budget configuration uses either 512 or 1024 optimization steps depending on the complexity of the target invariant set and the precision requirements of the specific experiment. This range proves sufficient for convergence across the evaluated network architectures and target activation patterns while providing computational bounds for practical implementation. The loss threshold is configured at $\tau = 0.01$, establishing a tight precision requirement for early stopping that ensures invariant set membership within acceptable tolerance levels while preventing unnecessary computational overhead from over-optimization.

\subsection{Hardware Configuration}

All experimental evaluations were conducted on NVIDIA A100 GPU configurations ranging from single-unit setups for smaller-scale experiments to four-unit parallel configurations for computationally intensive invariant set generation tasks. The implementation leverages the PyTorch framework with comprehensive CUDA acceleration capabilities, including state-of-the-art optimizations such as Flash Attention mechanisms that significantly improve memory efficiency and computational throughput during the attention operations within the diffusion model architecture.

Gradient checkpointing integration provides essential memory efficiency improvements that enable the deep computational graphs required for invariant set optimization while maintaining full gradient information for precise latent space updates. This approach proves critical for practical implementation on research hardware configurations, allowing complex invariant set generation tasks to execute within standard GPU memory constraints without compromising optimization accuracy or convergence properties.

\section{Frequency Domain Analysis}\label{appendix:frequency_analysis}

Proposed spectral analysis ensures that invariant set membership relies on semantic rather than imperceptible features.

\subsection{Filter Implementation}

The ideal low-pass filters were applied in frequency domain:
\begin{equation}
\mathcal{F}_{cutoff}(\mathbf{x}) = \mathcal{F}^{-1}(\mathbf{H}_{cutoff} \cdot \mathcal{F}(\mathbf{x}))
\end{equation}

where $\mathbf{H}_{cutoff}$ removes frequencies beyond the cutoff threshold.

\subsection{Analysis Protocol}

For each generated sample, a comprehensive spectral analysis protocol evaluates the semantic robustness of invariant set membership across multiple frequency bands. The analysis begins by applying ideal low-pass filters with cutoff frequencies ranging from 0.1 to 0.9 normalized to the Nyquist limit, systematically removing high-frequency components to isolate the contribution of different spectral bands to network activation patterns. Following the filtering operations, the network response is computed on each filtered image variant to quantify how activation patterns change as fine-scale details are progressively removed from the generated samples.

The deviation measurement phase quantifies the difference between filtered and unfiltered network responses, providing a quantitative assessment of the frequency dependence of invariant set membership. Finally, spectral preservation analysis plots the measured deviations across different frequency bands, revealing the frequency components essential for maintaining specific network activations and confirming the semantic rather than adversarial nature of the generated variations.

\subsection{Quality Interpretation}

Low deviations at high cutoff values indicate that invariance is preserved even when fine details are removed, confirming semantic rather than adversarial invariance. This pattern demonstrates that the generated invariant set members rely primarily on low-frequency semantic content rather than imperceptible high-frequency perturbations, validating the effectiveness of the frequency domain constraints in preventing adversarial solutions.

\section{Hyperparameter Optimization}\label{appendix:hyperparameters}

This section presents the comprehensive hyperparameter optimization study conducted to identify optimal configurations for invariant set generation. The optimization process evaluated multiple optimizer types, learning rates, and spectral filter configurations across diverse experimental conditions to establish robust parameter settings for reliable invariant set generation.

\subsection{Grid Search Methodology}

The hyperparameter optimization employed a systematic grid search approach across three key parameter categories: spectral filters, optimizers, and learning rates. The grid search was conducted using eight diverse test images, with eight invariant samples generated per image to ensure statistical reliability. For each parameter combination, the minimum $L_2$ loss over probability distributions (not logits) was recorded and analyzed to identify optimal configurations that consistently achieve tight constraint satisfaction across different visual content types.

The evaluation methodology prioritized configurations that demonstrated consistent performance across all test images rather than exceptional performance on specific cases. This approach ensures that selected hyperparameters provide reliable invariant set generation across diverse semantic contexts and visual patterns, supporting the method's generalizability and practical applicability.

\subsection{Spectral Filter Configuration}

The spectral filter optimization evaluated three distinct filter types with their associated parameter ranges to identify configurations that effectively prevent adversarial solutions while maintaining semantic coherence. Table~\ref{tab:filter_configs} presents the comprehensive evaluation of filter types and their parameter ranges.

\begin{table}[h!]
\centering
\begin{tabular}{lllc}
\toprule
\textbf{Filter Type} & \textbf{Parameter} & \textbf{Range} & \textbf{Configurations} \\
\midrule
Ideal & Cutoff Frequency & 0.2, 0.3, 0.4, 0.5, 0.6 & 5 \\
Gaussian & Sigma & 0.1, 0.15, 0.2, 0.25, 0.3, 0.35 & 6 \\
Butterworth & Cutoff Frequency & 0.2, 0.3, 0.4, 0.5, 0.6 & 5 \\
Butterworth & Order & 2, 4, 6, 8 & 4 \\
\midrule
\textbf{Total Combinations} & -- & -- & \textbf{20} \\
\bottomrule
\end{tabular}
\caption{Spectral filter configurations evaluated during hyperparameter optimization. Each filter type was systematically evaluated across its parameter range to identify optimal configurations for semantic coherence preservation while preventing adversarial solutions.}
\label{tab:filter_configs}
\end{table}

The Gaussian filter with sigma value 0.1 emerged as the optimal configuration, providing effective high-frequency noise suppression while preserving essential semantic content. This configuration demonstrated superior performance in maintaining semantic coherence across diverse visual patterns while effectively preventing the generation of adversarial artifacts that could compromise the interpretability of generated invariant sets.

\subsection{Optimizer Performance Analysis}

The optimizer evaluation compared four distinct optimization algorithms across multiple learning rate configurations to identify combinations that provide stable convergence and consistent constraint satisfaction. Table~\ref{tab:optimizer_performance} presents the comprehensive performance analysis across all evaluated optimizers.

\begin{table}[h!]
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Optimizer} & \textbf{Learning Rates} & \textbf{Min Loss} & \textbf{Max Loss} & \textbf{Std Dev} & \textbf{Convergence Quality} \\
\midrule
SGD & 1.0, 5.0, 10.0, 30.0, 50.0 & 0.0161 & 0.0674 & 0.0198 & Consistent \\
Adam & 1.0, 5.0, 10.0, 30.0, 50.0 & 0.0892 & 0.2451 & 0.0623 & Poor \\
Adagrad & 1.0, 5.0, 10.0, 30.0, 50.0 & 0.1134 & 0.3021 & 0.0751 & Poor \\
Shampoo & 1.0, 5.0, 10.0, 30.0, 50.0 & 0.0001 & 0.2051 & 0.0891 & Variable \\
\bottomrule
\end{tabular}
\caption{Optimizer performance comparison across learning rate configurations. Performance metrics represent aggregate statistics across eight test images with eight samples per image. Shampoo demonstrates the lowest minimum losses but high variability, while SGD provides consistent performance across all conditions.}
\label{tab:optimizer_performance}
\end{table}

The analysis reveals that Shampoo optimizer achieves the lowest minimum $L_2$ losses, indicating superior optimization capability under ideal conditions. However, Shampoo exhibits high variance across different samples and images, suggesting sensitivity to initialization and optimization landscape characteristics. SGD demonstrates more consistent performance with lower standard deviation, indicating reliable convergence properties that support reproducible invariant set generation across diverse experimental conditions.

\subsection{Final Configuration Selection}

Based on comprehensive analysis across all parameter combinations, the optimal configuration combines SGD optimizer with learning rate 10.0 and Gaussian filter with sigma 0.1. This configuration consistently appears among the top-performing parameter sets across all eight test images, demonstrating robust performance across diverse visual content types.

\subsection{Configuration Validation}

The validation analysis examined the relationship between spectral properties of original images and optimization difficulty, revealing insights into the factors that influence invariant set generation complexity. Images with spectral energy concentrated in lower frequency bands generally demonstrate easier optimization landscapes, requiring fewer optimization steps to achieve tight constraint satisfaction.

This observation suggests that the spectral characteristics of input images influence the optimization dynamics of invariant set generation, with low-frequency dominant images providing more favorable optimization conditions. The selected hyperparameter configuration demonstrates robust performance across this spectrum of optimization difficulties, supporting its applicability to diverse visual content types encountered in systematic experimental evaluation.

The comprehensive hyperparameter optimization establishes a principled foundation for invariant set generation experiments, ensuring that reported results reflect the method's capabilities under optimal configuration rather than suboptimal parameter choices that could artificially limit performance or introduce systematic biases in experimental evaluation.

\section{Neuron Selection Methodology}\label{appendix:neuron_selection}

The interpretable neurons were selected using the Semantic Lens framework \citep{dreyer2025mechanisticunderstandingvalidationlarge}, which provides systematic evaluation of neuron interpretability through quantitative semantic alignment metrics.

\subsection{Selection Criteria}

Neuron selection follows a rigorous evaluation process based on three complementary criteria that ensure both interpretability and experimental validity. The semantic alignment criterion requires neurons to achieve alignment scores $r > 0.85$, indicating high interpretability through strong correlation between neuron activations and human-interpretable visual concepts. This threshold ensures that selected neurons demonstrate clear, consistent responses to specific semantic patterns that can be reliably identified and validated through human evaluation.

Concept clarity represents the second selection criterion, requiring neurons to exhibit clear and consistent activation patterns across multiple examples of their target concept. This criterion eliminates neurons with ambiguous or inconsistent responses that could compromise the reliability of invariant set generation experiments. The diversity criterion ensures coverage of different semantic categories including geometric patterns, biological structures, and textural features, providing comprehensive evaluation across various types of visual concepts and preventing bias toward specific pattern types.

\subsection{Selected Neurons}

The experimental evaluation focuses on three carefully selected neurons that exemplify different categories of interpretable visual concepts. Neuron \#1656 demonstrates exceptional sensitivity to zebra striping patterns with an alignment score of $r = 0.945$, representing geometric pattern recognition capabilities that respond consistently to high-contrast alternating stripe configurations across various contexts and scales. Neuron \#1052 specializes in honeycomb structures with an alignment score of $r = 0.880$, exhibiting strong activation for hexagonal cellular patterns that appear in both natural and artificial contexts.

Neuron \#421 focuses on Gyromitra morphology with the highest alignment score of $r = 0.952$, responding specifically to convoluted, brain-like surface textures characteristic of certain fungal structures. These three neurons represent well-understood, semantically interpretable units with high activation specificity, providing reliable targets for invariant set generation experiments while covering diverse semantic categories that enable comprehensive evaluation of the proposed method's capabilities across different types of visual concepts.


\begin{figure}[p]
  \centering
  \includegraphics[height=0.2\textheight]{figures/appendix/sae_407.pdf}
  \caption{Appendix results - Class 407 (ambulance) - Neuron \#1807: flashing emergency lights. Generated images demonstrate semantic diversity while maintaining identical activation levels (32 samples, 1024 optimization steps).}
  \label{fig:appendix_407}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[height=0.2\textheight]{figures/appendix/sae_822.pdf}
  \caption{Appendix results - Class 822 (steel drum) - Neuron \#1935: reflective metal finish. Generated images demonstrate semantic diversity while maintaining identical activation levels (32 samples, 1024 optimization steps).}
  \label{fig:appendix_822}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[height=0.2\textheight]{figures/appendix/sae_70.pdf}
  \caption{Appendix results - Class 70 (harvestman) - Neuron \#1581: thin, wiry legs. Generated images demonstrate semantic diversity while maintaining identical activation levels (32 samples, 1024 optimization steps).}
  \label{fig:appendix_70}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[height=0.2\textheight]{figures/appendix/sae_817.pdf}
  \caption{Appendix results - Class 817 (sports car) - Neuron \#1507: wide tires. Generated images demonstrate semantic diversity while maintaining identical activation levels (32 samples, 1024 optimization steps).}
  \label{fig:appendix_817}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[height=0.2\textheight]{figures/appendix/sae_804.pdf}
  \caption{Appendix results - Class 804 (soap dispenser) - Neuron \#1066: liquid soap inside. Generated images demonstrate semantic diversity while maintaining identical activation levels (32 samples, 1024 optimization steps).}
  \label{fig:appendix_804}
\end{figure}

\begin{table}[ht!]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Neuron} & \textbf{Concept} & \textbf{$L_2$ Loss} & \textbf{FID Score} & \textbf{Std Dev} \\
\midrule
\#1807 & Ambulance - Flashing Emergency Lights & 0.33 & 7.95 & 0.20 \\
\#1935 & Steel Drum - Reflective Metal Finish & 1.43 & 7.72 & 0.30 \\
\#1581 & Harvestman - Thin Wiry Legs & 0.40 & 7.73 & 0.32 \\
\#1507 & Sports Car - Wide Tires & 1.35 & 8.08 & 0.08 \\
\#1066 & Soap Dispenser - Liquid Soap Inside & 0.27 & 8.07 & 0.22 \\
\midrule
\textbf{Average} & -- & \textbf{0.76 $\pm$ 0.24} & \textbf{7.91} & \textbf{0.22} \\
\bottomrule
\end{tabular}
\caption{Extended quantitative evaluation results for additional ImageNet classes. $L_2$ losses computed on unbounded activation logits; FID scores computed against ImageNet-1k image statistics. Standard deviation represents variability across generated samples. Results averaged over 32 generated samples per neuron.}
\label{tab:appendix_results}
\end{table}

\clearpage
